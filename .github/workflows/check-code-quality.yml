name: Check code quality

# TODO determine when we launch CI automatically
# TODO handle CI on an orphan branch ?
# TODO don't fail on error
on:
  push:
    # branches:
    #   - 'feat**'

  pull_request:
    types: [opened, synchronize, reopened]

  workflow_dispatch:

env:
  SOURCES: src
  TESTS: tests

jobs:

  check-format:
    runs-on: ubuntu-latest
    name: Check format (black)
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/install-python
      - uses: psf/black@stable
        with:
          options: --check --verbose

  check-linting:
    runs-on: ubuntu-latest
    name: Check linting (ruff, flake8)
    steps:
      - uses: actions/checkout@v3      
      - uses: ./.github/actions/poetry-install      
      - run: poetry run ruff check --output-format=github . # used by pre-commit
        shell: bash
      - run: poetry run flake8 ${SOURCES} ${TESTS} --output-file .reports/flake8.txt # used by sonarqube
        shell: bash
      - uses: actions/upload-artifact@v3
        with:
          name: flake8          
          path: | # add a random file (.flake8) so .reports/ is saved as a dir
            .reports
            .flake8
          retention-days: 1

  check-typing:
    runs-on: ubuntu-latest
    name: Check typing (mypy)
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/poetry-install
      - run: poetry run mypy .
        shell: bash

  # TODO to be completed
  # check-vulnerabilities:
  #   runs-on: ubuntu-latest
  #   name: Check vulnerabilities (trivy)
  #   steps:
  #     - uses: actions/checkout@v3
  #     - uses: aquasecurity/trivy-action@master
  #       with:
  #         scan-type: 'fs'
  #         scan-ref: '.'

  run-unit-tests:
    runs-on: ubuntu-latest
    name: Run unit tests (pytest)
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/poetry-install
      - run: |
          set -x && poetry run pytest ${TESTS} \
            -m unit \
            --durations=0 \
            --error-for-skips \
            --cov=${SOURCES} \
            --cov-report=term \
            --cov-report=xml:.reports/coverage.xml \
            --junit-xml=.reports/TEST-pytests.xml \
        shell: bash
      - uses: irongut/CodeCoverageSummary@v1.3.0
        with: # see https://github.com/marketplace/actions/code-coverage-summary#inputs
          filename: .reports/coverage.xml
          badge: false
          fail_below_min: true
          format: text
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: console
          thresholds: "1 75" # as "low% high%" coverage: fail under "low", "high" is used for the badges
      - uses: actions/upload-artifact@v3
        with:
          name: pytest-unit
          path: |
            .coverage
            .reports
          retention-days: 1

  # TODO: what the integration tests should be, what is the difference from the unit tests ?
  # Should they be scheduled or run only when merging to the develop or main branch ?
  # Note that in the code below, the integration tests will not be counted for the code coverage.
  run-integration-tests:
    runs-on: ubuntu-latest
    name: Run integration tests (pytest)
    steps:
      - uses: actions/checkout@v3
      - uses: ./.github/actions/poetry-install
      - run: |
          set -x && poetry run pytest ${TESTS} \
            -m integration \
            --durations=0 \
            --error-for-skips \
            --cov=${SOURCES} \
            --cov-report=term \
            --cov-report=xml:.reports/coverage-integration.xml \
        shell: bash
      - uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: .reports/coverage-integration.xml
          badge: false
          fail_below_min: true
          format: text
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: console
          thresholds: "1 75"

  # TODO add when writen
  #  - sonar project configuration
  #  - export previous elements as reports for sonar
  # generate-quality-report:
  #   runs-on: ubuntu-latest
  #   name: Generate quality report (sonarqube)
  #   steps:
  #     - uses: actions/checkout@v3
  #     - uses: kitabisa/sonarqube-action@v1.2.0
  #       with:
  #         host: ${{ secrets.SONARQUBE_HOST }}
  #         login: ${{ secrets.SONARQUBE_TOKEN }}
  #         #password: ""



  # test-julien:
  #   runs-on: ubuntu-latest
  #   name: test
  #   needs: [check-linting, run-unit-tests]
  #   steps:
  #     - uses: actions/download-artifact@v3
  #       with:
  #         name: flake8
  #     - uses: actions/download-artifact@v3
  #       with:
  #         name: pytest-unit
  #     - name: Print the final result
  #       shell: bash
  #       run: |
  #         find .